<div otvl-web>
type: sf_q_img_in_card
src: /assets/images/k8s-local-dev/portVendres.jpg
alt: Article image
title: Vers Port Vendres
</div>

# Working locally with Kubernetes for Data Science

** Preview: **
![logo work in progess](/assets/images/common/wip.png "Logo work in progress") This is a work in progress.

## Introduction


While the use of Docker and a Kubernetes orchestrator for Data Science become more and more standard when relying on Cloud Computing,
two interesting questions remain open:

- how to work locally: this may be useful for debugging, to set-up the initial environment more quickly than when working remotely,
or more obviously to leverage local computing resources such as a GPU for a Data Science use case;
- how to deal with simple public cloud providers that don't provide you with an orchestrator

Those two questions may raise a third one when users such as Data Scientists or business users with less sharp technical knowledge than developpers
are involved in such use cases and still want to keep their autonomy.

This first blog article will focus on the first question, while a second one will deal with the second. In both cases, the simplicity of the solutions will be analyzed.

## How to work locally

Before choosing solutions, we will have a look at relevant use cases and their technical context.

## Choosing solutions

## Conclusion

Not yet

## References

This section provides you with useful references.

Not yet.
