<div otvl-web>
type: sf_q_img_in_card
src: /assets/images/local-cloud-mixed-use-data-science/versEtangDeSoulcem.jpg
alt: Article image
title: Vers l'Ã©tang de Soulcem
</div>

# Mixing local and cloud data access for Data Science

![logo work in progess](/assets/images/common/wip.png "Logo work in progress")

** Preview: ** this is a work in progress.

## Introduction

Cloud Computing services offer great opportunities to Data Science projects,
however, as both local and cloud processing must often coexist,
the data access must be designed carefully.

After browsing available solutions for the support of various use cases,
this article discusses their implementations.

You will find useful references at the bottom of this page.

## Use cases and organisational constraints

### Data Science use cases and the Data Lake

The article
[Data Science and Big Data: Two Very Different Beasts](https://www.thoughtworks.com/insights/blog/data-science-and-big-data-two-very-different-beasts)
provides a very good definition of what Data Science is with respect to its use of Big Data.
This article also emphasizes that  
_"An unfortunate aspect of big data is that we look to the largest companies
to see what solutions they have engineered to compete in their markets.
But these companies hardly represent the challenges faced by most organizations."_

Indeed, there is a wide range of Data Science types of use cases,
and as some of them require the fast processing of large datasets
the assumption is often made that a Big Data platform is required.
While this is almost always the case when integrating Data Analytics results,
many Data Science applications do not require such a specialized infrastructure.

This is important to keep in mind as we may find more convenient technical solutions to be applied.

### Going beyond the Data Lake 

As we can stay too easily focused on solutions built around existing Data Lake products,
it is important to keep requirements and solutions as separate as possible.
I found the article
_"[How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh](https://martinfowler.com/articles/data-monolith-to-mesh.html)"_
 very enlightening concerning this question, the two main challenges that it describes being:

- the increasing number of data sources, along with their various organisation origins,
- and the increasing number of innovation use cases requiring specific data processing.

The article also explains how existing platforms shape the architecture of the solutions
around the data processing pipelines, making it difficult to integrate new data sources
as those pipelines are monolithic with respect to the organization.

Concerning the _Move to a Distributed Data Mesh_
 I let you read through this excellent article if you didn't already know it.
Some important consequences of implementing such an architecture are:

- that a reusable dataset scope is no more restricted to raw data like it was in a Data Lake,
  and it can now include the result of any intermediate processing of this data 
  if it is relevant for cross-domain reuse;
- it can even be provided through advanced data services such as ones found for instance
  with graph or time-series databases;
- that those datasets have to be considered as products, reusing the existing know-how of building
  any other software product;
- that the data processing pipelines are reshaped and this time aligned with the domain boundaries;
- those datasets product services being naturally provided by their owner domains.

### Domain driven architecture

We could represent such data services composition opportunities on a schema like the one below
(the arrows come from the consumer to the provider).
Each domain is represented by a colour, providing data services, built upon data engineering tools,
and that can be organized in pipelines.
We create thus a mesh of data services the same way we do for other kind of services. 

<div otvl-web>
type: sf_q_img_in_card
src: /assets/images/local-cloud-mixed-use-data-science/local_cloud_mixed_use_ds_mesh.jpg
alt: Domain Data Services Mesh schema
title: Domain Data Services Mesh
class_: self_width_img
</div>

The data services gouvernance is clear and enables cross-domain reuse when wanted,
as soon as service level agreements are defined.
The potential cross-domain reuse of this resulting _"domain data as a product"_
makes our initial assumption, mixing local and cloud data access, even more likely.

To conclude on the functional point of view, we can see that this move
towards a distributed data mesh provides all the organisational agility
required for answering new challenges concerning Data Science,
while taking benefit of know-how and best practices from other technical domains.

Perhaps will you also find interesting some real-world examples
related to the application of a product thinking approach
for the data governance in the article:
"[The curse of the data lake monster](https://www.thoughtworks.com/insights/blog/curse-data-lake-monster)"

We will consider the implementation questions in the following sections,
as this is the domain where Data Science has very specific requirements.
The services and pipelines implementation responsibilities are naturally defined
with the same domain boundaries as the business services they provide,
and the architecture does not forbid technical solutions reuse,
while not making it mandatory.

## Solutions and operational constraints

The number and the variety of the solutions is intimidating at first, see for instance:
[Next-Gen Data Lakes and Analytics Platforms](https://www.slideshare.net/AmazonWebServices/nextgen-data-lakes-and-analytics-platforms-aws-summit-sydney).
We will first hear what analysts and technology specialists have to say,
before looking at the existing infrastructure products for their support.

### General recommendations

The article already mentioned
[Data Science and Big Data: Two Very Different Beasts](https://www.thoughtworks.com/insights/blog/data-science-and-big-data-two-very-different-beasts)
also emphasizes that _"conversion Should Scale Before Collection"_.
Applying this recommendation when looking for Data Science infrastructure solutions
means that those solutions

- must be adaptable to a continuous change of requirements
  concerning the use of existing or newly created data services
  and their implementations through data transformation pipelines;
- must be flexible regarding the multiplicity of needs:
  business users, refresh rates, confidentiality and compliancy rules,
  processing tools and database engines;
- must enable Data Scientists to work efficiently
  but also with the required security and reliability, from the Proof of Concept products
  up to effective applications integrating their solutions in production.

Those ideas are also developed in the article  
- [ten Characteristics of a Modern Data Architecture](https://www.eckerson.com/articles/ten-characteristics-of-a-modern-data-architecture)

### Infrastructure products

## Implementations

## Conclusion and further perspective

## References

**Articles and presentations**

- [Data Science and Big Data: Two Very Different Beasts](https://www.thoughtworks.com/insights/blog/data-science-and-big-data-two-very-different-beasts)
- [How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh](https://martinfowler.com/articles/data-monolith-to-mesh.html)
- [The curse of the data lake monster](https://www.thoughtworks.com/insights/blog/curse-data-lake-monster)
- [Ten Characteristics of a Modern Data Architecture](https://www.eckerson.com/articles/ten-characteristics-of-a-modern-data-architecture)
- [Next-Gen Data Lakes and Analytics Platforms](https://www.slideshare.net/AmazonWebServices/nextgen-data-lakes-and-analytics-platforms-aws-summit-sydney)
- [Building Big Data Storage Solutions (Data Lakes) for Maximum Flexibility](https://docs.aws.amazon.com/whitepapers/latest/building-data-lakes/building-data-lake-aws.html)
- [Continuous Delivery for Machine Learning](https://martinfowler.com/articles/cd4ml.html)
- [Modern Data Lake with Minio : Part 1](https://blog.minio.io/modern-data-lake-with-minio-part-1-716a49499533)
- [Everything a Data Scientist Should Know About Data Management](https://www.kdnuggets.com/2019/10/data-scientist-data-management.html)
- [How LinkedIn, ... and Netflix are Solving Data Management ... for Machine Learning Solutions](https://www.kdnuggets.com/2019/08/linkedin-uber-lyft-airbnb-netflix-solving-data-management-discovery-machine-learning-solutions.html)

**Reference materials**

- [martinFowler - DataLake](https://martinfowler.com/bliki/DataLake.html)

** Security related **

- [Amazon Cognito](https://docs.aws.amazon.com/cognito/latest/developerguide/what-is-amazon-cognito.html)
- [OpenStack Swift ACLs](https://docs.openstack.org/swift/latest/overview_acl.html)
